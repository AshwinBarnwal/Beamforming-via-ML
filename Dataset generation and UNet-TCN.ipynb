{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Generation:"
      ],
      "metadata": {
        "id": "7CHsZKogZx-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPqh2v_Da-l0",
        "outputId": "e9191822-2b9e-4d1b-9045-eff1487e88c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Running on cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q numpy cython librosa soundfile\n",
        "!pip install -q pyroomacoustics\n",
        "!pip install -q --upgrade numba==0.56.4 llvmlite==0.39\n",
        "!pip install -q tqdm\n",
        "\n",
        "import numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "import librosa, soundfile as sf, json, random, glob\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm, trange\n",
        "import pyroomacoustics as pra\n",
        "\n",
        "FS, DUR, L = 16000, 10.0, int(16000 * 10)\n",
        "MIC_POS = np.array([[-0.05, 0, 0],\n",
        "                    [ 0.05, 0, 0],\n",
        "                    [-0.08, 0.045, 0.04],\n",
        "                    [ 0.08, 0.045, 0.04]]).T  # (3,4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FS, DUR, L = 16000, 10.0, int(16000 * 10)"
      ],
      "metadata": {
        "id": "LTZKrw_MpQG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f84K6MthoZCA",
        "outputId": "ec861c6a-ed71-4edf-c6e4-c62fcd1884f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _load(path, fs=FS, length=L):\n",
        "    y, sr = sf.read(path)\n",
        "    if y.ndim > 1: y = y.mean(1)\n",
        "    if sr!=fs: y = librosa.resample(y.astype(np.float32), sr, fs)\n",
        "    return np.pad(y, (0, max(0, length-len(y))))[:length]\n",
        "\n",
        "def _normalize_rms(x, target_db=-25):\n",
        "    rms = np.sqrt(np.mean(x**2) + 1e-12)\n",
        "    scalar = (10**(target_db/20)) / rms\n",
        "    return x * scalar\n",
        "\n",
        "def simulate_two_speakers(tgt_wav, itf_wav,\n",
        "                          overlap=0.5,\n",
        "                          room_rng=((3,3,1.5),(8,8,2.5)),\n",
        "                          rt60_rng=(.1,.6),\n",
        "                          seed=None,\n",
        "                          target_rms_db=-25):\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    mix_4ch   : (4, L) float32 – target + interferer, RMS-normalised\n",
        "    clean_ref : (L,)   float32 – mic-0 target, RMS-normalised\n",
        "    meta      : dict   – room / placement info\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # 1) random room\n",
        "    dim  = rng.uniform(*np.array(room_rng), 3)\n",
        "    rt60 = rng.uniform(*rt60_rng)\n",
        "    abscoef = float(np.mean(pra.inverse_sabine(rt60, dim)))\n",
        "    room = pra.ShoeBox(dim, fs=FS, absorption=abscoef, max_order=17)\n",
        "\n",
        "    # 2) mic array\n",
        "    offset = dim/2; offset[2] = 1.5\n",
        "    room.add_microphone_array(pra.MicrophoneArray(MIC_POS + offset[:, None], FS))\n",
        "\n",
        "    # 3) load 4-s clips\n",
        "    tgt, itf = _load(tgt_wav), _load(itf_wav)\n",
        "\n",
        "    # 4) add sources\n",
        "    tgt_pos = np.array([0.0, -0.06, 0.0]) + offset\n",
        "    room.add_source(tgt_pos, tgt)\n",
        "\n",
        "    theta = rng.uniform(np.deg2rad(5), np.deg2rad(355))\n",
        "    r     = rng.uniform(0.5, 3.0)\n",
        "    itf_pos = np.clip(tgt_pos + r*np.array([np.cos(theta), np.sin(theta), 0.0]),\n",
        "                      [0,0,0.1], dim-0.1)\n",
        "    room.add_source(itf_pos, itf, delay=(1-overlap)*2.0)\n",
        "\n",
        "    # 5) simulate mixture\n",
        "    room.simulate()\n",
        "    multi_mix = room.mic_array.signals[:, :L]            # (4, L)\n",
        "\n",
        "    # 6) build clean reference (target RIR only)\n",
        "    clean_mics = np.stack(\n",
        "        [np.convolve(tgt, room.rir[m][0])[:L] for m in range(len(MIC_POS.T))]\n",
        "    )\n",
        "    clean_ref = clean_mics[0]\n",
        "\n",
        "    # 7) RMS normalise\n",
        "    mix_norm   = _normalize_rms(multi_mix, target_db=target_rms_db)\n",
        "    clean_norm = _normalize_rms(clean_ref,  target_db=target_rms_db)\n",
        "\n",
        "    # 8) metadata\n",
        "    meta = dict(\n",
        "        room_dim = dim.tolist(),\n",
        "        rt60     = float(rt60),\n",
        "        src_pos  = tgt_pos.tolist(),\n",
        "        itf_pos  = itf_pos.tolist()\n",
        "    )\n",
        "\n",
        "    return mix_norm.astype(np.float32), clean_norm.astype(np.float32), meta"
      ],
      "metadata": {
        "id": "rPEtgcVO_yGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.openslr.org/resources/12/dev-clean.tar.gz -O dev-clean.tar.gz\n",
        "!tar -xzf dev-clean.tar.gz"
      ],
      "metadata": {
        "id": "1G4EZuXn4Tyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LIB_DIR=Path(\"./LibriSpeech/dev-clean\")\n",
        "OUT_DIR=Path(\"/content/drive/MyDrive/audio_dataset/10s\"); OUT_DIR.mkdir(parents=True,exist_ok=True)\n",
        "wav_files=[p for p in LIB_DIR.rglob(\"*.flac\") if p.stat().st_size>0]\n",
        "\n",
        "def pick_two(): return random.sample(wav_files,2)\n",
        "\n",
        "def make_sim_dataset(n=100):\n",
        "    for idx in trange(n, desc=\"Generating\"):\n",
        "        while True:\n",
        "            try:\n",
        "                src,itf=pick_two()\n",
        "                mix,clean,meta=simulate_two_speakers(src,itf,seed=random.randint(0,2**32-1))\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Retry {idx}: {e}\"); continue\n",
        "        sf.write(OUT_DIR/f\"mix_{idx:05d}.wav\",mix.T,FS,subtype=\"PCM_16\")\n",
        "        sf.write(OUT_DIR/f\"clean_{idx:05d}.wav\",clean,FS,subtype=\"PCM_16\")\n",
        "        json.dump(meta, open(OUT_DIR/f\"meta_{idx:05d}.json\",'w'))\n",
        "    print(\"✓ Done\")\n",
        "\n",
        "# run it\n",
        "# make_sim_dataset(100)"
      ],
      "metadata": {
        "id": "pCVq3CPG4_mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_sim_dataset(90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHKJ2cPJ7MmV",
        "outputId": "a0bc7322-4276-486f-e2c0-a4d2de629635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating:  48%|████▊     | 43/90 [00:57<00:48,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 43: zero-size array to reduction operation maximum which has no identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating:  64%|██████▍   | 58/90 [01:11<00:31,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 58: zero-size array to reduction operation maximum which has no identity\n",
            "Retry 58: evaluation of parameters failed. room may be too large for required RT60.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating:  69%|██████▉   | 62/90 [01:15<00:25,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 62: zero-size array to reduction operation maximum which has no identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating:  70%|███████   | 63/90 [01:16<00:27,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 63: zero-size array to reduction operation maximum which has no identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating:  82%|████████▏ | 74/90 [01:28<00:14,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 74: zero-size array to reduction operation maximum which has no identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 90/90 [01:44<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNet-Model work begins from here"
      ],
      "metadata": {
        "id": "w4atIU1nZrSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    mix, clean, meta = zip(*batch)   # each is a tuple length B\n",
        "    return list(mix), list(clean), list(meta)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    ds, batch_size=4, shuffle=True, collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "aDw31tLCr_J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ───────────────────────────────\n",
        "# Small helpers\n",
        "# ───────────────────────────────\n",
        "def conv2d(in_ch, out_ch, k=3, s=1, p=1):\n",
        "    return nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=True)\n",
        "\n",
        "def deconv2d(in_ch, out_ch, k=3, s=2, p=1, op=1):\n",
        "    return nn.ConvTranspose2d(in_ch, out_ch, kernel_size=k, stride=s,\n",
        "                              padding=p, output_padding=op, bias=True)\n",
        "\n",
        "class TCNBlock(nn.Module):\n",
        "    \"\"\"One dilated 1-D convolution block (causal=false).\"\"\"\n",
        "    def __init__(self, ch, dilation):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(ch, ch, kernel_size=3,\n",
        "                              padding=dilation, dilation=dilation)\n",
        "        self.norm = nn.BatchNorm1d(ch)\n",
        "        self.act  = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.act(self.norm(self.conv(x)))\n",
        "        return x + y                      # residual\n",
        "\n",
        "class StackedTCN(nn.Module):\n",
        "    \"\"\"3 × 8 stacked TCN blocks, each with 128 channels.\"\"\"\n",
        "    def __init__(self, ch=128, stacks=3, layers=8):\n",
        "        super().__init__()\n",
        "        blocks = []\n",
        "        for _ in range(stacks):\n",
        "            dil = 1\n",
        "            for _ in range(layers):\n",
        "                blocks.append(TCNBlock(ch, dil))\n",
        "                dil *= 2\n",
        "        self.net = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):   # x: [B, 128, T]\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "jsTVVPKp1xXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetTCNMaskNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Input  : [B, 6,  F,  T]   (6 = |Y0|, 3×cosIPD, AF_src, AF_noise)\n",
        "    Output : [B, 2,  F,  T]   (complex mask: [Real, Imag])  – or set out_ch=1 for IRM\n",
        "    \"\"\"\n",
        "    def __init__(self, out_ch=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # ── Encoder\n",
        "        self.enc1 = nn.Sequential(conv2d(6,  32, s=2), nn.PReLU(), nn.BatchNorm2d(32))\n",
        "        self.enc2 = nn.Sequential(conv2d(32, 64, s=2), nn.PReLU(), nn.BatchNorm2d(64))\n",
        "        self.enc3 = nn.Sequential(conv2d(64,128, s=2), nn.PReLU(), nn.BatchNorm2d(128))\n",
        "\n",
        "        # ── Decoder\n",
        "        self.dec1 = nn.Sequential(deconv2d(128, 64), nn.PReLU(), nn.BatchNorm2d(64))\n",
        "        self.dec2 = nn.Sequential(deconv2d(128, 32), nn.PReLU(), nn.BatchNorm2d(32))\n",
        "        self.dec3 = nn.Sequential(deconv2d(64,  out_ch), nn.PReLU())\n",
        "\n",
        "        # ── Temporal module\n",
        "        self.tcn = StackedTCN(ch=128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x : [B, 6, F, T]   (F≈257)\n",
        "        \"\"\"\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)                 # [B,32, F/2,  T/2]\n",
        "        e2 = self.enc2(e1)                # [B,64, F/4,  T/4]\n",
        "        e3 = self.enc3(e2)                # [B,128,F/8,  T/8]\n",
        "\n",
        "        # Collapse freq-axis for TCN → treat (B*F') as batch\n",
        "        B, C, F_, T_ = e3.shape\n",
        "        tcn_in = e3.permute(0,2,1,3).reshape(B*F_, C, T_)  # [B·F',128,T']\n",
        "\n",
        "        tcn_out = self.tcn(tcn_in)                          # same shape\n",
        "        e3 = tcn_out.reshape(B, F_, C, T_).permute(0,2,1,3)\n",
        "\n",
        "        # Decoder with skips\n",
        "        d1 = self.dec1(e3)                                  # [B,64, F/4, T/4]\n",
        "        d1 = torch.cat([d1, e2], dim=1)                    # skip\n",
        "\n",
        "        d2 = self.dec2(d1)                                  # [B,32, F/2, T/2]\n",
        "        d2 = torch.cat([d2, e1], dim=1)                    # skip\n",
        "\n",
        "        mask = self.dec3(d2)                                # [B,out_ch,F,T]\n",
        "        mask = torch.tanh(mask)                             # keep mask bounded\n",
        "        return mask"
      ],
      "metadata": {
        "id": "hQx1eMR31yH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"/content/drive/MyDrive/audio_dataset\")\n",
        "mix_paths   = sorted(glob.glob(str(DATA_DIR / \"mix_*.wav\")))\n",
        "clean_paths = sorted(glob.glob(str(DATA_DIR / \"clean_*.wav\")))\n",
        "\n",
        "class MixDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.mix_paths   = sorted(Path(data_dir).glob(\"mix_*.wav\"))\n",
        "        self.clean_paths = sorted(Path(data_dir).glob(\"clean_*.wav\"))\n",
        "        self.meta_paths  = sorted(Path(data_dir).glob(\"meta_*.json\"))\n",
        "        assert len(self.mix_paths)==len(self.clean_paths)==len(self.meta_paths)\n",
        "\n",
        "    def __len__(self): return len(self.mix_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mix,   _ = sf.read(self.mix_paths[idx])      # (L,4)\n",
        "        clean, _ = sf.read(self.clean_paths[idx])    # (L,)\n",
        "        with open(self.meta_paths[idx]) as f:\n",
        "            meta = json.loads(f.read())\n",
        "        mix = mix.T.astype(np.float32)               # (4,L)\n",
        "        return mix, clean.astype(np.float32), meta"
      ],
      "metadata": {
        "id": "aFLcSq86bjbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stft_multi(x, n_fft=512, hop=256):\n",
        "    # x : (M,L)  ->  (M,F,T) complex\n",
        "    return np.stack([\n",
        "        librosa.stft(ch, n_fft=n_fft, hop_length=hop, window=\"hann\")\n",
        "        for ch in x\n",
        "    ])\n",
        "\n",
        "def make_feature_tensor(mix_4ch, meta, sr=16000, n_fft=512, hop=256):\n",
        "    \"\"\"\n",
        "    mix_4ch : (4,L) float32  mixture\n",
        "    meta    : dict           contains room_dim, src_pos, itf_pos\n",
        "    Returns feats [6,F,T] float32, Y_stft [4,F,T] complex64\n",
        "    \"\"\"\n",
        "    # 1) STFT\n",
        "    Y = stft_multi(mix_4ch)                    # (4,F,T)\n",
        "    Y0, mag0 = Y[0], np.abs(Y[0])\n",
        "\n",
        "    # 2) IPD (mic-0 reference)\n",
        "    ipd     = np.angle(Y[1:]) - np.angle(Y0)   # (3,F,T)\n",
        "    cos_ipd = np.cos(ipd)                      # (3,F,T)\n",
        "\n",
        "    # 3) Expected phase delays\n",
        "    c  = 343.0\n",
        "    F  = Y.shape[1]\n",
        "    f  = np.linspace(0, sr/2, F)[:, None]      # (F,1)\n",
        "\n",
        "    # absolute mic coordinates\n",
        "    room_dim = np.array(meta[\"room_dim\"])\n",
        "    offset   = room_dim / 2; offset[2] = 1.5   # same logic as simulator\n",
        "    p_abs    = (MIC_POS + offset[:,None])      # (3,4)\n",
        "    p0_abs   = p_abs[:,0]\n",
        "    pj_abs   = p_abs[:,1:]                     # (3,3)\n",
        "\n",
        "    # --- target (near-field)\n",
        "    s_abs    = np.array(meta[\"src_pos\"])\n",
        "    dist_0   = np.linalg.norm(p0_abs - s_abs)\n",
        "    dist_j   = np.linalg.norm(pj_abs.T - s_abs, axis=1)       # (3,)\n",
        "    exp_tgt  = 2*np.pi * f @ ((dist_j - dist_0)[None] / c)    # (F,3)\n",
        "\n",
        "    # --- interferer (far-field planar)\n",
        "    i_abs    = np.array(meta[\"itf_pos\"])\n",
        "    doa_noise= (i_abs - p0_abs) / np.linalg.norm(i_abs - p0_abs)\n",
        "    d_vec    = pj_abs.T - p0_abs                               # (3,3)\n",
        "    proj     = d_vec @ doa_noise                               # (3,)\n",
        "    exp_noise= 2*np.pi * f @ (proj[None] / c)                  # (F,3)\n",
        "\n",
        "    # angle features\n",
        "    AF_src   = np.sum(np.cos(ipd.transpose(1,0,2) - exp_tgt[:,:,None]), axis=1)\n",
        "    AF_noise = np.sum(np.cos(ipd.transpose(1,0,2) - exp_noise[:,:,None]), axis=1)\n",
        "\n",
        "    feats = np.concatenate(\n",
        "        [mag0[None], cos_ipd, AF_src[None], AF_noise[None]], axis=0\n",
        "    ).astype(np.float32)                                      # (6,F,T)\n",
        "\n",
        "    return torch.from_numpy(feats), torch.from_numpy(Y)"
      ],
      "metadata": {
        "id": "1ICi_kjJ11Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = UNetTCNMaskNet().to(device)\n",
        "opt = torch.optim.Adam(net.parameters(), lr=2e-3)\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "def collate_fn(batch):\n",
        "    mix, clean, meta = zip(*batch)   # each is a tuple length B\n",
        "    return list(mix), list(clean), list(meta)\n",
        "\n",
        "ds = MixDataset(DATA_DIR)\n",
        "loader = torch.utils.data.DataLoader(ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "for epoch in range(5):  # Demo: 5 epochs\n",
        "    net.train()\n",
        "    total_loss = 0\n",
        "    for mix, clean, meta in tqdm(loader, desc=f\"Epoch {epoch}\"):\n",
        "        feats, Y, X = [], [], []\n",
        "\n",
        "        for m, c, meta_dict in zip(mix, clean, meta):\n",
        "            f, y = make_feature_tensor(m, meta_dict)\n",
        "            x    = librosa.stft(np.array(c), n_fft=512, hop_length=256, window=\"hann\")\n",
        "            feats.append(f)\n",
        "            Y.append(y)\n",
        "            X.append(torch.from_numpy(x))\n",
        "\n",
        "        feats = torch.stack(feats).to(device)        # [B,6,F,T]\n",
        "        Y     = torch.stack(Y).to(device)           # [B,4,F,T]\n",
        "        X     = torch.stack(X).to(device)            # [B,F,T]\n",
        "\n",
        "        mask  = net(feats)                       # [B,2,F,T]\n",
        "        M     = torch.complex(mask[:,0], mask[:,1])   # [B,F,T]\n",
        "\n",
        "        S_hat = M[:, None] * Y                        # [B,4,F,T]\n",
        "        loss  = mse(S_hat.real[:,0], X.real) + mse(S_hat.imag[:,0], X.imag)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"[Epoch {epoch}] Avg Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(net.state_dict(), \"unet_tcn_masknet.pt\")\n",
        "print(\"✓ Model saved to 'unet_tcn_masknet.pt'\")"
      ],
      "metadata": {
        "id": "4wPqS_z62D8v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "e689605f-a1f1-4062-ad29-692969f24229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   0%|          | 0/25 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 66 but got size 1 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-3773305063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mX\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# [B,F,T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmask\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# [B,2,F,T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mM\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# [B,F,T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-15-2009112790.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# up  ×2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0me2c\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# up  ×2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 66 but got size 1 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d(in_ch, out_ch, k=3, s=1, p=1):\n",
        "    return nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=True)\n",
        "\n",
        "def deconv2d(in_ch, out_ch, k=3, s=2, p=1, op=1):\n",
        "    return nn.ConvTranspose2d(in_ch, out_ch, kernel_size=k, stride=s,\n",
        "                              padding=p, output_padding=op, bias=True)\n",
        "\n",
        "class TCNBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(ch, ch, 3, padding=dilation, dilation=dilation)\n",
        "        self.norm = nn.BatchNorm1d(ch)\n",
        "        self.act  = nn.PReLU()\n",
        "    def forward(self, x):\n",
        "        return x + self.act(self.norm(self.conv(x)))\n",
        "\n",
        "class StackedTCN(nn.Module):\n",
        "    def __init__(self, ch=128, stacks=3, layers=8):\n",
        "        super().__init__()\n",
        "        blocks = []\n",
        "        for _ in range(stacks):\n",
        "            dil = 1\n",
        "            for _ in range(layers):\n",
        "                blocks.append(TCNBlock(ch, dil))\n",
        "                dil *= 2\n",
        "        self.net = nn.Sequential(*blocks)\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class UNetTCNMaskNet(nn.Module):\n",
        "    def __init__(self, in_ch=6, out_ch=2):\n",
        "        super().__init__()\n",
        "        # encoder\n",
        "        self.enc1 = nn.Sequential(conv2d(in_ch, 32, s=2), nn.PReLU(), nn.BatchNorm2d(32))\n",
        "        self.enc2 = nn.Sequential(conv2d(32, 64, s=2), nn.PReLU(), nn.BatchNorm2d(64))\n",
        "        self.enc3 = nn.Sequential(conv2d(64,128, s=2), nn.PReLU(), nn.BatchNorm2d(128))\n",
        "        # temporal\n",
        "        self.tcn  = StackedTCN(128)\n",
        "        # decoder\n",
        "        self.dec1 = nn.Sequential(deconv2d(128, 64), nn.PReLU(), nn.BatchNorm2d(64))\n",
        "        self.dec2 = nn.Sequential(deconv2d(128, 32), nn.PReLU(), nn.BatchNorm2d(32))\n",
        "        self.dec3 = nn.Sequential(deconv2d(64,  out_ch), nn.PReLU())\n",
        "\n",
        "    # ─────────────────────────────────────────────\n",
        "    # helper stays unchanged\n",
        "    def crop_like(self, src, ref):\n",
        "        \"\"\"Center‑crop `src` so its spatial (F,T) dims match `ref`.\"\"\"\n",
        "        _, _, H, W = src.shape\n",
        "        _, _, h, w = ref.shape\n",
        "        if H == h and W == w:\n",
        "            return src\n",
        "        dH, dW = (H - h) // 2, (W - w) // 2\n",
        "        return src[:, :, dH:dH + h, dW:dW + w]\n",
        "\n",
        "    # ─────────────────────────────────────────────\n",
        "    def forward(self, x):           # x: [B, 6, F, T]\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)           # [B,32,F/2,T/2]\n",
        "        e2 = self.enc2(e1)          # [B,64,F/4,T/4]\n",
        "        e3 = self.enc3(e2)          # [B,128,F/8,T/8]\n",
        "\n",
        "        # Temporal TCN\n",
        "        B, C, F_, T_ = e3.shape\n",
        "        tcn_in  = e3.permute(0, 2, 1, 3).reshape(B * F_, C, T_)  # [B·F',128,T']\n",
        "        tcn_out = self.tcn(tcn_in).reshape(B, F_, C, T_).permute(0, 2, 1, 3)\n",
        "        e3 = tcn_out                                                # still [B,128,F/8,T/8]\n",
        "\n",
        "        # Decoder with safe crops\n",
        "        d1 = self.dec1(e3)                      # up ×2 → [B,64,F/4’,T/4’]\n",
        "        d1 = self.crop_like(d1, e2)             # crop to e2’s size\n",
        "        d1 = torch.cat([d1, e2], dim=1)         # [B,128,F/4,T/4]\n",
        "\n",
        "        d2 = self.dec2(d1)                      # up ×2 → [B,32,F/2’,T/2’]\n",
        "        d2 = self.crop_like(d2, e1)             # crop to e1’s size\n",
        "        d2 = torch.cat([d2, e1], dim=1)         # [B,64,F/2,T/2]\n",
        "\n",
        "        mask = torch.tanh(self.dec3(d2))        # final up ×2 → [B,2,F,T]\n",
        "        return mask\n"
      ],
      "metadata": {
        "id": "q8WEYyxs4zfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stft_multi(x, n_fft=512, hop=256):\n",
        "    return np.stack([librosa.stft(ch, n_fft=n_fft, hop_length=hop, window=\"hann\")\n",
        "                     for ch in x])\n",
        "\n",
        "def make_feature_tensor(mix_4ch, meta, sr=16000, n_fft=512, hop=256):\n",
        "    Y = stft_multi(mix_4ch)                          # (4,F,T)\n",
        "    mag0 = np.abs(Y[0])\n",
        "    ipd  = np.angle(Y[1:]) - np.angle(Y[0])          # (3,F,T)\n",
        "    cos_ipd = np.cos(ipd)                            # (3,F,T)\n",
        "\n",
        "    # expected phase delays\n",
        "    c=343.0; F=Y.shape[1]; f=np.linspace(0,sr/2,F)[:,None]\n",
        "    room_dim=np.array(meta[\"room_dim\"]); offset=room_dim/2; offset[2]=1.5\n",
        "    p_abs=(MIC_POS + offset[:,None]); p0=p_abs[:,0]; pj=p_abs[:,1:]\n",
        "\n",
        "    s=np.array(meta[\"src_pos\"]);  i=np.array(meta[\"itf_pos\"])\n",
        "    dist0=np.linalg.norm(p0-s);       distj=np.linalg.norm(pj.T-s, axis=1)\n",
        "    exp_tgt=2*np.pi*f@((distj-dist0)[None]/c)         # (F,3)\n",
        "    doa=(i-p0)/np.linalg.norm(i-p0); proj=(pj.T-p0)@doa\n",
        "    exp_noise=2*np.pi*f@(proj[None]/c)                # (F,3)\n",
        "\n",
        "    AF_src  = np.sum(np.cos(ipd.transpose(1,0,2)-exp_tgt[:,:,None]), axis=1)\n",
        "    AF_noise= np.sum(np.cos(ipd.transpose(1,0,2)-exp_noise[:,:,None]),axis=1)\n",
        "\n",
        "    feats=np.concatenate([mag0[None], cos_ipd, AF_src[None], AF_noise[None]],0)\n",
        "    return torch.from_numpy(feats), torch.from_numpy(Y)"
      ],
      "metadata": {
        "id": "6LwCnEVk417R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def steering_vector(sr=16000, n_fft=512):\n",
        "    f = np.linspace(0, sr/2, n_fft//2+1)             # (F,)\n",
        "    p0 = MIC_POS[:,0]; s = np.array([0, -0.06, 0])   # relative to array\n",
        "    dist0=np.linalg.norm(p0-s); dist = np.linalg.norm(MIC_POS.T - s, axis=1)\n",
        "    tau = (dist - dist0)[None] / 343.0               # (1,M)\n",
        "    return torch.from_numpy(np.exp(-2j*np.pi*f[:,None]*tau)).to(torch.complex64) # (F,4)\n",
        "\n",
        "alpha_src = steering_vector()"
      ],
      "metadata": {
        "id": "wMnz3GEZ44jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mvdr_framewise(Y, M, alpha_src, alpha_smooth=0.8, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      Y : (B, M, F, T) complex STFTs\n",
        "      M : (B, F, T) complex mask\n",
        "      alpha_src : float in (0,1), EMA update for target spatial cov\n",
        "    Returns:\n",
        "      X_hat : (B, F, T) complex – beamformed output\n",
        "    \"\"\"\n",
        "    B, Mics, F, T = Y.shape\n",
        "    S_hat = M[:, None] * Y        # (B, M, F, T)\n",
        "    N_hat = Y - S_hat             # (B, M, F, T)\n",
        "\n",
        "    # Init frequency-wise spatial covariances\n",
        "    Phi = torch.eye(Mics, dtype=Y.dtype, device=Y.device)[None, None, :, :].repeat(B, F, 1, 1)  # (B, F, 4, 4)\n",
        "    X_hat = []\n",
        "\n",
        "    for t in range(T):\n",
        "        n = N_hat[..., t]                     # (B, M, F)\n",
        "        n = n.permute(0, 2, 1)                # (B, F, M)\n",
        "        Phi_inst = torch.einsum(\"bfi,bfj->bfij\", n, n.conj())   # (B, F, M, M)\n",
        "\n",
        "        Phi = alpha_smooth * Phi + (1 - alpha_smooth) * Phi_inst\n",
        "\n",
        "        s = S_hat[..., t].permute(0, 2, 1)                     # (B, M, F)\n",
        "        s = s.permute(0, 2, 1)                # (B, F, M)\n",
        "        phi_s = torch.einsum(\"bfi,bfj->bfij\", s, s.conj())      # (B, F, M, M)\n",
        "        phi_s = alpha_src * phi_s\n",
        "\n",
        "        # Beamforming vector\n",
        "        try:\n",
        "            Phi_inv = torch.linalg.inv(Phi + eps * torch.eye(Mics, dtype=Y.dtype, device=Y.device)[None, None])\n",
        "        except RuntimeError:\n",
        "            Phi_inv = torch.linalg.pinv(Phi + eps * torch.eye(Mics, dtype=Y.dtype, device=Y.device)[None, None])\n",
        "\n",
        "        v = s                             # (B, F, M)\n",
        "        numerator = torch.einsum(\"bfij,bfj->bfi\", Phi_inv, v)\n",
        "        denom = torch.einsum(\"bfi,bfi->bf\", v.conj(), numerator).real + eps\n",
        "        w = (numerator / denom[..., None])   # (B, F, M)\n",
        "\n",
        "        y = Y[..., t].permute(0, 2, 1)        # (B, F, M)\n",
        "        x_t = torch.einsum(\"bfi,bfi->bf\", w.conj(), y)  # (B, F)\n",
        "        X_hat.append(x_t)\n",
        "\n",
        "    return torch.stack(X_hat, dim=-1)         # (B, F, T)\n",
        "\n",
        "def complex_istft(X, n_fft=512, hop=256):\n",
        "    # X: (B,F,T) complex -> (B,L) real\n",
        "    B = X.shape[0]\n",
        "    out=[]\n",
        "    for b in range(B):\n",
        "        out.append(librosa.istft(X[b].cpu().numpy(), hop_length=hop, window=\"hann\"))\n",
        "    maxL = max(len(x) for x in out)\n",
        "    out = [np.pad(x,(0,maxL-len(x))) for x in out]\n",
        "    return torch.from_numpy(np.stack(out)).to(X.real.device)\n",
        "\n",
        "def si_sdr(est, ref, eps=1e-8):\n",
        "    # est, ref: (B,L)\n",
        "    ref_energy = torch.sum(ref**2, dim=-1, keepdim=True)+eps\n",
        "    s_target = torch.sum(est*ref, dim=-1, keepdim=True)/ref_energy * ref\n",
        "    e_noise  = est - s_target\n",
        "    return 10*torch.log10((torch.sum(s_target**2, -1)+eps)/(torch.sum(e_noise**2,-1)+eps))"
      ],
      "metadata": {
        "id": "oCks3igZ46Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MixDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.mix_paths   = sorted(Path(data_dir).glob(\"mix_*.wav\"))\n",
        "        self.clean_paths = sorted(Path(data_dir).glob(\"clean_*.wav\"))\n",
        "        self.meta_paths  = sorted(Path(data_dir).glob(\"meta_*.json\"))\n",
        "        assert len(self.mix_paths)==len(self.clean_paths)==len(self.meta_paths)\n",
        "\n",
        "    def __len__(self): return len(self.mix_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mix, _   = sf.read(self.mix_paths[idx]);  mix=mix.T.astype(np.float32)\n",
        "        clean,_  = sf.read(self.clean_paths[idx])\n",
        "        meta     = json.load(open(self.meta_paths[idx]))\n",
        "        return mix, clean.astype(np.float32), meta\n",
        "\n",
        "def collate_fn(batch):\n",
        "    mix, clean, meta = zip(*batch)\n",
        "    return list(mix), list(clean), list(meta)\n",
        "\n",
        "ds = MixDataset(\"/content/drive/MyDrive/audio_dataset\")\n",
        "loader = torch.utils.data.DataLoader(ds, batch_size=2, shuffle=True,\n",
        "                                     num_workers=2, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "wt_aXGNn5CE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = UNetTCNMaskNet().to(device)\n",
        "opt = torch.optim.Adam(net.parameters(), lr=2e-3)\n",
        "\n",
        "for epoch in range(2):                         # demo 2 epochs\n",
        "    net.train(); running = 0.0\n",
        "    for mix, clean, meta in tqdm(loader, desc=f\"Epoch {epoch}\"):\n",
        "        feats_b, Y_b, clean_b = [], [], []\n",
        "        for m, c, md in zip(mix, clean, meta):\n",
        "            f, Y = make_feature_tensor(m, md)\n",
        "            feats_b.append(f);  Y_b.append(Y);  clean_b.append(torch.from_numpy(c))\n",
        "\n",
        "        feats = torch.stack(feats_b).float().to(device)      # [B,6,F,T]\n",
        "        Y     = torch.stack(Y_b).to(device)                  # [B,4,F,T]\n",
        "        clean_wave = torch.stack(clean_b).to(device)         # [B,L]\n",
        "\n",
        "        mask = net(feats)                                    # [B,2,Fm,Tm]\n",
        "\n",
        "        # ── align mask & mixture spatial dims ────────────────────────────  ### NEW ###\n",
        "        _, _, Fm, Tm = mask.shape\n",
        "        _, _, Fy, Ty = Y.shape\n",
        "        F_common, T_common = min(Fm, Fy), min(Tm, Ty)\n",
        "        mask = mask[:, :, :F_common, :T_common]              # crop mask\n",
        "        Y    = Y[:, :, :F_common, :T_common]                 # crop mixture\n",
        "        # ------------------------------------------------------------------  ### NEW ###\n",
        "\n",
        "        M    = torch.complex(mask[:,0], mask[:,1])           # [B,F,T]\n",
        "\n",
        "        X_hat = mvdr_framewise(Y, M, alpha_src)              # (B,F,T)\n",
        "        x_hat = complex_istft(X_hat)                         # (B,L)\n",
        "\n",
        "        clean_wave = clean_wave[..., :x_hat.shape[-1]]\n",
        "        loss_si = -si_sdr(x_hat, clean_wave).mean()\n",
        "\n",
        "        # MSE on reference‑mic STFT (cropped to F_common,T_common)\n",
        "        X_ref = torch.view_as_real(Y[:,0])                   # (B,F,T,2)\n",
        "        loss_tf = F.mse_loss((M*Y[:,0]).real, X_ref[...,0]) \\\n",
        "                + F.mse_loss((M*Y[:,0]).imag, X_ref[...,1])\n",
        "\n",
        "        loss = 0.5*loss_si + 0.5*loss_tf\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        running += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch}  avg loss {running/len(loader):.4f}\")\n",
        "\n",
        "torch.save(net.state_dict(), \"/content/drive/MyDrive/audio_dataset/masknet_mvdr.pth\")\n",
        "print(\"✓ model + MVDR training complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "M08ufaW_5FIW",
        "outputId": "62d3ab1d-df8e-40b8-c24d-354a0caa190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   0%|          | 0/50 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (4) must match the size of tensor b (257) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-60-3257322504.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mM\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# [B,F,T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvdr_framewise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_src\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# (B,F,T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_istft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# (B,L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-59-3787330402.py\u001b[0m in \u001b[0;36mmvdr_framewise\u001b[0;34m(Y, M, alpha_src, alpha_smooth, eps)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# (B, F, M)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mphi_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bfi,bfj->bfij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# (B, F, M, M)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mphi_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_src\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mphi_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Beamforming vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (257) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}