{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba058757",
   "metadata": {},
   "source": [
    "Directly training a binary mask for every time frame (not frequency) by appending the DoA information to all the microphone's STFT's repeatedly for each time frame\n",
    "\n",
    "Uses surrogate gradient descent to get continuous gradients during backpropagation while still outputting binary masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10f47e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from torchaudio.transforms import Spectrogram, InverseSpectrogram\n",
    "\n",
    "def normalize_mag(mag, threshold=1e-4):\n",
    "    frame_norms = torch.norm(mag, dim=-1, keepdim=True)  # [B, T, 1]\n",
    "    max_norm = frame_norms.max(dim=1, keepdim=True).values  # [B, 1, 1]\n",
    "    scale = torch.where(frame_norms > threshold, frame_norms, torch.ones_like(frame_norms))\n",
    "    scale_factor = max_norm / scale\n",
    "    return mag * scale_factor\n",
    "\n",
    "def normalize_audio_from_file(filepath, output_path, n_fft=512, hop_length=128):\n",
    "    # Load audio\n",
    "    waveform, sr = torchaudio.load(filepath)  # [1, T] or [C, T]\n",
    "    waveform = waveform.mean(dim=0, keepdim=True)  # Ensure mono\n",
    "    waveform = waveform.unsqueeze(0)  # [1, 1, T]\n",
    "\n",
    "    # STFT and ISTFT setup\n",
    "    spec = Spectrogram(n_fft=n_fft, hop_length=hop_length, power=None)\n",
    "    istft = InverseSpectrogram(n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # Forward STFT\n",
    "    X = spec(waveform.squeeze(0))  # [1, F, T]\n",
    "    mag = X.abs()                  # [1, F, T]\n",
    "    phase = X.angle()             # [1, F, T]\n",
    "\n",
    "    # Transpose to [B, T, F] for compatibility with normalize_mag\n",
    "    mag_t = mag.permute(0, 2, 1)  # [1, T, F]\n",
    "    norm_mag_t = normalize_mag(mag_t)\n",
    "    norm_mag = norm_mag_t.permute(0, 2, 1)  # [1, F, T]\n",
    "\n",
    "    # Reconstruct complex STFT with original phase\n",
    "    X_norm = norm_mag * torch.exp(1j * phase)\n",
    "\n",
    "    # ISTFT to waveform\n",
    "    output_waveform = istft(X_norm)  # [1, T]\n",
    "    output_waveform = output_waveform.squeeze(0)  # [T]\n",
    "\n",
    "    # Save output\n",
    "    sf.write(output_path, output_waveform.cpu().numpy(), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c5f87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import Spectrogram, InverseSpectrogram\n",
    "\n",
    "class PerFrameGainNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_freq_bins: int, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        # input_dim = 4 * n_freq_bins  (flattened magnitudes) + 3 (DoA)\n",
    "        self.input_dim = 4 * n_freq_bins + 3\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()  # ensures g_t in [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, mag4ch: torch.Tensor, doa: torch.Tensor):\n",
    "        \n",
    "        B, T, F, C = mag4ch.shape\n",
    "        mag_flat = mag4ch.view(B, T, 4 * F)              # [B, T, 4F]\n",
    "        doa_exp = doa.unsqueeze(1).expand(B, T, 3)       # [B, T, 3]\n",
    "        inp = torch.cat([mag_flat, doa_exp], dim=-1)     # [B, T, 4F+3]\n",
    "        inp2 = inp.view(B * T, -1)                       # [B*T, 4F+3]\n",
    "        g = self.net(inp2)                               # [B*T, 1]\n",
    "        g = g.view(B, T)                                 # [B, T]\n",
    "\n",
    "    # Binary STE: threshold at 0.5, but allow gradient through original g\n",
    "        g_binary = (g > 0.5).float()\n",
    "        g_out = g + (g_binary - g).detach()              # STE: forward binary, backward real\n",
    "\n",
    "        return g_out\n",
    "\n",
    "\n",
    "class STFTHelper:\n",
    "    def __init__(self, n_fft=512, hop_length=128, power=None, pad_mode='reflect', device='cpu'):\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.spectrogram = Spectrogram(n_fft=n_fft, hop_length=hop_length, power=power, pad_mode=pad_mode).to(device)\n",
    "        self.istft = InverseSpectrogram(n_fft=n_fft, hop_length=hop_length).to(device)\n",
    "\n",
    "    def multichannel_stft(self, waveform_4ch: torch.Tensor):\n",
    "        \n",
    "        B, T, C = waveform_4ch.shape\n",
    "        x_reshaped = waveform_4ch.permute(0, 2, 1).contiguous()  # [B, 4, T]\n",
    "        x_reshaped = x_reshaped.view(B * C, T)                   # [B*4, T]\n",
    "        X = self.spectrogram(x_reshaped)                         # [B*4, F, T_stft]\n",
    "        FreqBins, Tstft = X.shape[-2], X.shape[-1]\n",
    "        X = X.view(B, C, FreqBins, Tstft)                         # [B, 4, F, T]\n",
    "        X = X.permute(0, 3, 2, 1).contiguous()                    # [B, T, F, 4]\n",
    "        mag4ch = X.abs()                                          # [B, T, F, 4]\n",
    "        phase4ch = X.angle()                                      # [B, T, F, 4]\n",
    "        return mag4ch, phase4ch\n",
    "\n",
    "    def mono_stft(self, waveform_1ch: torch.Tensor):\n",
    "\n",
    "        X = self.spectrogram(waveform_1ch)                        # [B, F, T_stft]\n",
    "        X = X.permute(0, 2, 1).contiguous()                        # [B, T_stft, F]\n",
    "        mag1ch = X.abs()\n",
    "        return mag1ch\n",
    "\n",
    "    def istft_reconstruct(self, mag: torch.Tensor, phase: torch.Tensor = None):\n",
    "\n",
    "        if mag.ndim == 3 and mag.shape[1] != self.n_fft // 2 + 1:\n",
    "            # assume input is [B, T_stft, F]\n",
    "            mag = mag.permute(0, 2, 1).contiguous()  # to [B, F, T_stft]\n",
    "        if phase is not None:\n",
    "            complex_spec = mag * torch.exp(1j * phase)\n",
    "        else:\n",
    "            # Use magnitude and zero phase\n",
    "            complex_spec = mag\n",
    "        waveform = self.istft(complex_spec)\n",
    "        return waveform\n",
    "\n",
    "# Loss Function\n",
    "def stft_gain_loss(pred_gain: torch.Tensor, clean_mag: torch.Tensor, ref_mag: torch.Tensor):\n",
    "\n",
    "    pred_gain = pred_gain.unsqueeze(-1)                        # [B, T_stft, 1]\n",
    "    estimated_mag = pred_gain * ref_mag                        # [B, T_stft, F]\n",
    "    loss = F.mse_loss(estimated_mag, clean_mag)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a9d04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class FourChannelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects a list of tuples (path_4ch_wav, path_clean_wav, doa_vector)\n",
    "    Each 4ch wav has shape [T, 4]; clean wav has shape [T]\n",
    "    \"\"\"\n",
    "    def __init__(self, file_list, stft_helper, device='cpu'):\n",
    "        self.file_list = file_list\n",
    "        self.stft_helper = stft_helper\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_4ch, path_clean, doa_vec = self.file_list[idx]\n",
    "        # Load audio\n",
    "        audio_4ch, fs1 = sf.read(path_4ch)\n",
    "        audio_clean, fs2 = sf.read(path_clean)\n",
    "        assert fs1 == fs2, \"Sampling rate mismatch\"\n",
    "        audio_4ch = torch.from_numpy(audio_4ch).float().to(self.device)\n",
    "        audio_clean = torch.from_numpy(audio_clean).float().to(self.device)\n",
    "        doa = torch.from_numpy(np.array(doa_vec, dtype=np.float32)).to(self.device)\n",
    "\n",
    "        # Compute STFT magnitudes\n",
    "        mag4ch, _ = self.stft_helper.multichannel_stft(audio_4ch.unsqueeze(0))  # [1, Tstft, F, 4]\n",
    "        mag_clean = self.stft_helper.mono_stft(audio_clean.unsqueeze(0))        # [1, Tstft, F]\n",
    "    \n",
    "        mag4ch = mag4ch.squeeze(0)     # [Tstft, F, 4]\n",
    "        mag_clean = mag_clean.squeeze(0)  # [Tstft, F]\n",
    "\n",
    "        # Normalize only reference (channel 0)\n",
    "        mag4ch_ref = normalize_mag(mag4ch[..., 0])  # [Tstft, F]\n",
    "        mag4ch[..., 0] = mag4ch_ref  # Replace normalized ref channel\n",
    "        #mag_clean=normalize_mag(mag_clean)\n",
    "        return mag4ch, mag_clean, doa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79b30d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file_list = [(\"/kaggle/input/singlechannelaudios/multichannel_input.wav\", \"/kaggle/input/singlechannelaudios/target.wav\", [0.0,-1.0,0.0])]  # <-- fill with your data\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "stft_helper = STFTHelper(n_fft=512, hop_length=128, power=None, pad_mode='reflect', device=device)\n",
    "\n",
    "dataset = FourChannelDataset(file_list, stft_helper, device=device)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Instantiate model\n",
    "dummy_item = dataset[0]\n",
    "_, mag_clean_dummy, _ = dummy_item\n",
    "T_stft, n_freq_bins = mag_clean_dummy.shape\n",
    "model = PerFrameGainNet(n_freq_bins=n_freq_bins , hidden_dim=256).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_state = None\n",
    "num_epochs = 10  # adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for mag4ch, mag_clean, doa in loader:\n",
    "        # mag4ch: [B, Tstft, F, 4], mag_clean: [B, Tstft, F], doa: [B,3]\n",
    "        mag4ch = mag4ch.to(device)\n",
    "        mag_clean = mag_clean.to(device)\n",
    "        doa = doa.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        gains = model(mag4ch, doa)               # [B, Tstft]\n",
    "        ref_mag = mag4ch[..., 0]                  # [B, Tstft, F]\n",
    "        loss = stft_gain_loss(gains, mag_clean, ref_mag)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * mag4ch.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "    if epoch_loss < best_loss:\n",
    "        best_gains=gains\n",
    "        best_loss = epoch_loss\n",
    "        best_state = model.state_dict().copy()\n",
    "\n",
    "# Save best model weights\n",
    "torch.save(best_state, \"best_gain_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757705e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def apply_gains_and_write(input_path: str, gains: torch.Tensor, output_path: str,\n",
    "                          n_fft=512, hop_length=128):\n",
    "\n",
    "    # Load multichannel audio\n",
    "    waveform, sample_rate = torchaudio.load(input_path)  # [4, T]\n",
    "    channel1 = waveform[0:1, :]                           # [1, T]\n",
    "\n",
    "    # Compute STFT\n",
    "    stft_transform = T.Spectrogram(n_fft=n_fft, hop_length=hop_length, power=None)\n",
    "    X = stft_transform(channel1)                          # [1, F, T_stft]\n",
    "    \n",
    "    # Apply gain\n",
    "    mag = X.abs()                                         # [1, F, T_stft]\n",
    "    phase = X.angle()                                     # [1, F, T_stft]\n",
    "\n",
    "    if gains.ndim == 1:\n",
    "        gains = gains.unsqueeze(0)                        # [1, T_stft]\n",
    "    gains = gains.unsqueeze(1)                            # [1, 1, T_stft]\n",
    "    \n",
    "    est_mag = mag * gains                                 # [1, F, T_stft]\n",
    "    complex_spec = est_mag * torch.exp(1j * phase)        # [1, F, T_stft]\n",
    "\n",
    "    # Inverse STFT\n",
    "    istft_transform = T.InverseSpectrogram(n_fft=n_fft, hop_length=hop_length)\n",
    "    enhanced_waveform = istft_transform(complex_spec)     # [1, T]\n",
    "\n",
    "    # Save output\n",
    "    torchaudio.save(output_path, enhanced_waveform.cpu(), sample_rate)\n",
    "\n",
    "    return enhanced_waveform"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
